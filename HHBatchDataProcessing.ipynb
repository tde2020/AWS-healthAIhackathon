{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Batch Data Processing\n",
    "Batch processing of  Electronic Medical Reports (EMR) using Amazon Comprehend Medical\n",
    "\n",
    "Assumption: A row dataset such as MTSamples exists.\n",
    "- The medical reports (in pdf form) can be extracted using Textract and data can be inserted to a dataset similar to MTSamples. The example notebook in medical document processing workshop in [1.Data_Processing.ipynb](https://github.com/aws-samples/amazon-textract-and-comprehend-medical-document-processing) can be used for extracting transcript text.\n",
    "- Data can be also be directly inserted using online user input.\n",
    "\n",
    "# Contents\n",
    "\n",
    "1. [Objective](#Objective)\n",
    "1. [Background](#Background)\n",
    "1. [Setup Environment](#Setup-Environment)\n",
    "1. [Load and Explore Data](#Load-and-Explore-Data)\n",
    "1. [Data Sampling for modeling](#Data-Sampling-for-modeling)\n",
    "1. [Combine the dataset](#Combine-the-dataset)\n",
    "1. [Save the processed file](#Save-the-processed-file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Objective \n",
    "This notebook is the preprocessing step to prepare a batch of medical records for model training. This will use Comprehend Medical to extract medical key words (e.g. fever, wheezing, injury) from doctors's transcripts, patients input and organize them into data frame that will be used as features in model training. Afterwards this trained model will be used to  classify the medical specialties in a new transcription text. In real life use case, the model predictions can be used for automatic reference to respective specialist, provide medical information, recommendations for nutritions & suppliments, relavent exercises & therapies etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "**Dataset**: Medical transcription data scraped from mtsamples.com. This dataset is used in the medical document processing sample notebook. (`./data/mtsample.csv`). You can find the raw dataset at [kaggle](https://www.kaggle.com/tboyle10/medicaltranscriptions). \n",
    "\n",
    "**Amazon Comprehend Medical**: Comprehend Medical detects useful information in unstructured clinical text. As much as 75% of all health record data is found in unstructured text Amazon Comprehend Medical uses Natural Language Processing (NLP) models to sort through text for valuable information.\n",
    "\n",
    "**Supported Languages**: Amazon Comprehend Medical only detects medical entities in English language texts. However I have used a sample prediction use case in the ModelDeployment notebook using a German transcript which is first translated to English and used for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup Environment\n",
    "\n",
    "\n",
    "- **import** some useful libraries (as in any Python notebook)\n",
    "- **configure** the S3 bucket and folder where data should be stored (to keep our environment tidy)\n",
    "- **connect** to Amazon Comprehend(with [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)) and SageMaker in particular (with the [sagemaker SDK](https://sagemaker.readthedocs.io/en/stable/)), to use the cloud services\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # For matrix operations and numerical processing\n",
    "import pandas as pd  # For munging tabular data\n",
    "import time\n",
    "import os\n",
    "\n",
    "# reuse frunctions from medical document processing notebooks\n",
    "from util.preprocess import *  # helper function for classification reports\n",
    "\n",
    "# setting up SageMaker parameters\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "#bucket_prefix = \"emr-mtSample\"  # Location in the bucket to store our files\n",
    "sgmk_session = sagemaker.Session()\n",
    "\n",
    "sgmk_client = boto_session.client(\"sagemaker\")  ## API for sagemaker\n",
    "cm_client = boto3.client(service_name='comprehendmedical', use_ssl=True, region_name = 'us-east-1') ## API for comprehend medical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load and Explore Data\n",
    "\n",
    "MTSamples dataset (`./data/mtsample.csv`)\n",
    "\n",
    "**Columns in the dataset**:\n",
    "\n",
    "* `description`: Short description of transcription (string)\n",
    "* `medical_specialty`: Medical specialty classification of transcription (string)\n",
    "* `sample_name`: Transcription title\n",
    "* `transcription`: Transcribed doctors' notes\n",
    "* `keywords`: Relevant keywords from transcription\n",
    "\n",
    "To train the model the features are extracted from processing the `transcription` column using Amazon Comprehend Medical. The `medical_specialty`column is used as the label for the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./data/mtsamples.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up dataset\n",
    "\n",
    "Check for empty columns and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=0) ## check for missing information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the *33* rows with `transcription` is null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['transcription'].isnull()==False].reset_index()\n",
    "df.isnull().sum(axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore dataset by medical speciality\n",
    "\n",
    "Observe the distribution of medical reports by medical speciality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add patient_id for reference\n",
    "df['id']=df.index\n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "sns.countplot(y='medical_specialty',order=df['medical_specialty'].value_counts().index, data=df)  #df.medical_specialty.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Sampling for modeling\n",
    "\n",
    "#### Business Question:\n",
    "How often have we searched information about illnesses, prescriptions, symptoms to find health information?\n",
    "Any patient would be intersted to know information about possible illnesses, what can improve the situation with respect to nutritions, suppliments, exercises, therapies or which specilization of doctors should be consulted.\n",
    "\n",
    "#### ML problem to resolve:\n",
    "Multiclass classfication for patient input based on medical conditions.\n",
    "\n",
    "#### Why we do data sampling at this step?  \n",
    "\n",
    "For demo purpose and data limitations, 6 medical specialities are chosen. The 6 categories are:\n",
    "\n",
    "    1: \"Cardiovascular / Pulmonary\"   \n",
    "    2: \"Orthopedic\"   \n",
    "    3: \"Radiology\"   \n",
    "    4: \"General Medicine\"    \n",
    "    5: \"Gastroenterology\"   \n",
    "    6: \"Neurology\"\n",
    "    \n",
    "A sample of 200 records from each category is selected randomly. Surgery and Consultation data categories are removed as they can belong to multiple medical specialities. (e.g. Surgery can be on different organs.) Categories with less than 200 records are not taken.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sampling from 6 categories: 200 samples each\n",
    "\n",
    "Extract the medical conditions using Amazon Comprehend Medical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nSample=200 ## number to process the medical terms in a batch \n",
    "# Do not run with 200 if you just want to test, as this will cost around $100!!!\n",
    "# Use 20 for time & cost consideration if you want to test the funciton, however this is not enough for good model accuracy!!\n",
    "\n",
    "df_list_cp, patient_ids_cp = subpopulation_comprehend(df, ' Cardiovascular / Pulmonary',sampleSize=nSample)\n",
    "df_list_or, patient_ids_or = subpopulation_comprehend(df, ' Orthopedic',sampleSize=nSample)\n",
    "df_list_ra, patient_ids_ra = subpopulation_comprehend(df, ' Radiology',sampleSize=nSample)\n",
    "df_list_gm, patient_ids_gm = subpopulation_comprehend(df, ' General Medicine',sampleSize=nSample)\n",
    "df_list_ga, patient_ids_ga = subpopulation_comprehend(df, ' Gastroenterology',sampleSize=nSample)\n",
    "df_list_nu, patient_ids_nu = subpopulation_comprehend(df, ' Neurology',sampleSize=nSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch processing using Amazon Comprehend Medical \n",
    "\n",
    "Extract all the medical_conditions for each patient, together with the confidence score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to process a multiple records\n",
    "def extractMCbatch(transcriptionList,patientIDList):\n",
    "    df_final = pd.DataFrame()\n",
    "    \n",
    "    if(len(transcriptionList)!=len(patientIDList)):\n",
    "        return(\"Error! different length!\")\n",
    "    \n",
    "    ## In this for loop, gererate a wide dataframe with extracted medical condition from each item, together with the corresponding ID \n",
    "    for item,patient_id in zip(transcriptionList,patientIDList):\n",
    "#        print(\"processing patient_id:\",patient_id )\n",
    "        df_ind = extractMC_v2(item)\n",
    "        df_ind['ID']=patient_id\n",
    "        df_final=df_final.append(df_ind)\n",
    "        \n",
    "    # remove the duplicated entries if any\n",
    "    df_final=df_final.sort_values(by=['ID','MEDICAL_CONDITION']).drop_duplicates(['ID','MEDICAL_CONDITION'],keep='last')\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test function *extractMCbatch* and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted_cp=extractMCbatch(df_list_cp,patient_ids_cp)\n",
    "df_extracted_or=extractMCbatch(df_list_or,patient_ids_or)\n",
    "df_extracted_ra=extractMCbatch(df_list_ra,patient_ids_ra)\n",
    "df_extracted_gm=extractMCbatch(df_list_gm,patient_ids_gm)\n",
    "df_extracted_ga=extractMCbatch(df_list_ga,patient_ids_ga)\n",
    "df_extracted_nu=extractMCbatch(df_list_nu,patient_ids_nu)\n",
    "\n",
    "## plot the results\n",
    "topN=40 ## the number for top conditions\n",
    "threshold_score=0.8 ##the threshold of confidence score\n",
    "df_cp_plot=mc_barplot(df_extracted_cp, threshold_score,topN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Combine the dataset\n",
    "\n",
    "There are 6 datasets, one per spefiality. These 6 datasets need to be consolidated for the model training.\n",
    "\n",
    "### Gaps:\n",
    "The dataset is in long format, meaning that each row represents a single medical condition for one patients. If a patient *John* has 10 medical conditions, there will be 10 rows. Thus, there are varied number of rows of each patient. \n",
    "### Solutions:\n",
    "To make the dataset easier for ML algorithm to handle, it need to be converted into wide format, one row for one patient. Instead of keeping all the existing medical conditions I have selected top 40 medical conditions from each category as input features. Note that `40` here is an arbitrary number chosen after few tests. With 20, model accuracy was close to 0. \n",
    "\n",
    "In the following cell, function *`retrieve_mcList(df, nFeature=40,threshold=0.8)`* helps to retrieve the features from each subset with `nFeature`(default=40)  as specified number of features and `threshold`(default=0.8) as the confidence threshold. Outputs from *`retrieve_mcList()`*:\n",
    "\n",
    "+ top medical conditions list,\n",
    "+ cleaned dataframe through converting to lower case, merg *etc*.\n",
    "\n",
    "`Target column`: as it is a classification problem, a new column called `Label`is created with the number defined for the speciality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relavent records\n",
    "mcListcp, df_grpcp=retrieve_mcList(df_extracted_cp, 40)\n",
    "mcListor, df_grpor=retrieve_mcList(df_extracted_or, 40)\n",
    "mcListra, df_grpra=retrieve_mcList(df_extracted_ra, 40)\n",
    "mcListgm, df_grpgm=retrieve_mcList(df_extracted_gm, 40)\n",
    "mcListga, df_grpga=retrieve_mcList(df_extracted_ga, 40)\n",
    "mcListnu, df_grpnu=retrieve_mcList(df_extracted_nu, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grpcp['Label']=1 # 'Cardiovascular / Pulmonary'\n",
    "df_grpor['Label']=2 # 'Orthopedic'\n",
    "df_grpra['Label']=3 # 'Radiology'\n",
    "df_grpgm['Label']=4 # 'General Medicine'\n",
    "df_grpga['Label']=5 # 'Gastroenterology'\n",
    "df_grpnu['Label']=6 # 'Neurology'\n",
    "\n",
    "df_fulllist = df_grpcp.append([df_grpor, df_grpra, df_grpgm, df_grpga, df_grpnu])\n",
    "fullmcList=list(set(mcListcp+mcListor+mcListra+mcListgm+mcListga+mcListnu))\n",
    "df_combined_full=df_mc_generator(df_fulllist, fullmcList ,colname_other=['ID',\"Label\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Save the processed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_full.to_csv(\"./data/processed_combined_extract.csv\",index=False)\n",
    "\n",
    "# Upload to s3 for future use - customize the bucket name given here(hhtestdata) if you try out the code\n",
    "fileUploadPath = os.path.join(\"./data\", \"processed_combined_extract.csv\")\n",
    "boto3.Session().resource(\"s3\").Bucket('hhtestdata').Object(\"processed_combined_extract.csv\").upload_file(\n",
    "    fileUploadPath\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
