{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Building the model to classify electronic medical records (EMR)\n",
    "\n",
    "In the batch data processing using [HHBatchDataProcessing.ipynb](./HHBatchDataProcessing.ipynb), I have prepared a dataset by extracting medical records that had medical speciality of the following categories on the MTSamples data. Those records have been passed through Comprehend Medical to extract medical key workds and the data is converted to a flat file having the feature set and the label.\n",
    "\n",
    "    1: \"Cardiovascular / Pulmonary\"\n",
    "    2: \"Orthopedic\"\n",
    "    3: \"Radiology\"\n",
    "    4: \"General Medicine\"\n",
    "    5: \"Gastroenterology\"\n",
    "    6: \"Neurology\"\n",
    "\n",
    "\n",
    "In this notebook, I will be using the extracted dataset to create a classification model.\n",
    "\n",
    "The goal of this experiment is to do a **Next step Prediction** which aims at predicting the speciality needed for a patient with certain diseases. In practice, the model could be used to analyze a medical transcription in real-time that can be used to provide a recommended referals to respective specialist, provide medical information related to health condition, provide nutrition or suppliments, exercises or available therapies that can help to improve quality of life and life style decisions. In this way it can establish a portal to integrate health care providers to the patients. \n",
    "\n",
    "The input for the prediction is the EMR as a pdf file with doctor's notes about the patient or patients notes about their illness described in free form. This unstructured free form text is passed through Comprehend Medical to extract the medical terms which can then be used to predict medical speciality using the trained model.\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Objective](#Objective)\n",
    "1. [Setup Environment](#Setup-Environment)\n",
    "1. [Load and Explore the Dataset](#Load-and-Explore-Dataset)\n",
    "1. [Prepare Dataset for Model Training](#Prepare-Dataset-for-Model-Training)\n",
    "1. [Linear learner Algorithm](#Linear-learner-Algorithm)\n",
    "1. [Train the Model](#Train-the-Model)\n",
    "1. [Deploy and Evaluate the Model](#Deploy-and-Evaluate-the-Model)\n",
    "1. [Hyperparameter Optimization](#Hyperparameter-Optimization)\n",
    "1. [Inference Example](#Inference-Example)\n",
    "1. [Conclusion](#Conclusion)\n",
    "1. [Clean up resources](#Clean-up-resources)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Objective\n",
    "Predict health condition according to the EMR\n",
    "\n",
    "Input: Free text of patients health condition written by the patient, a prescription or a doctors transcript.\n",
    "\n",
    "Final goal: According to the predicted Health speciality, provide information about health recommendations and medical speciality.  (this programe is ending at the prediciton state but during a product implementation it can be integrated to a health care provider database which can provide information about illnesse, doctors list, nutrition or suppliment list, therapies etc.) \n",
    "\n",
    "Challenges:\n",
    "- Dataset is limited and a larger dataset will help to train the model with more accuracy.\n",
    "- Dataset contains limited amount of health conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup Environment\n",
    "\n",
    "- **import** some useful libraries (as in any Python notebook)\n",
    "- **configure** the S3 bucket and folder where data should be stored (to keep our environment tidy)\n",
    "- **connect** to AWS in general (with [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)) and SageMaker in particular (with the [sagemaker SDK](https://sagemaker.readthedocs.io/en/stable/)), to use the cloud services\n",
    "- **Upgrade** SageMaker to the latest version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install textract-trp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # For matrix operations and numerical processing\n",
    "import pandas as pd  # For munging tabular data\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "# reuse frunctions from medical document processing notebooks\n",
    "#from util.classification_report import generate_classification_report, predict_from_numpy_V2  # helper function for classification reports\n",
    "from util.Pipeline import extractTextract, extractMedical\n",
    "from util.preprocess import *\n",
    "\n",
    "# import record processing functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker.amazon.amazon_estimator import RecordSet, get_image_url\n",
    "\n",
    "# setting up SageMaker parameters\n",
    "import pkg_resources\n",
    "pkg_resources.require(\"sagemaker>2.9.2\") \n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "bucket_prefix = \"emr-mtSample\"  # Location in the bucket to store our files\n",
    "sgmk_session = sagemaker.Session()\n",
    "sgmk_client = boto_session.client(\"sagemaker\")\n",
    "sgmk_role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load and Explore Dataset\n",
    "\n",
    "Load the dataset prepared from the previous notebook [BatchDataProcessing](./BatchDataProcessing.ipynb). This dataset contains labelled data based on the medical speciality selected above and the medical features that were extracted from the electronic medical reports.\n",
    "\n",
    "You can find the processed dataset in the following location '/data/processed_combined_extract.csv'.\n",
    "\n",
    "*Demographics:*\n",
    "* `ID`: id of the patients (int)\n",
    "* `Label`: the medical condition (1-6 chosen categories)\n",
    "* The rest of the columns e.g. `fever`, `wheezing`: medical condition extracted from notes. The number indicate confidence of the symptom (float), there are 113 features in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_full=pd.read_csv(\"./data/processed_combined_extract.csv\")\n",
    "df_wide_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore correlation between the input variables and output one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrPlot(df_wide_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prepare-Dataset-for-Model-Training\n",
    "\n",
    "1. Convert Label to start from 0 than 1 as required in linear learner.\n",
    "2. Suffle and split the data into **Training (80%)**, **Validation (10%)**, and **Test (10%)** sets.\n",
    "3. Visualize data to see the number of records per category.\n",
    "\n",
    "The training and validation datasets will be used during the training (and tuning) phase, while the 'holdout' test set will be used afterwards to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use AWS classifier - linear learner multi classifier\n",
    "\n",
    "# transform labels to 0 index as it is required by linear learner to have labels starting 0\n",
    "df_wide_full['Label'] -= 1\n",
    "\n",
    "df_wide_full=df_wide_full.apply(pd.to_numeric, downcast='float', errors='coerce')\n",
    "\n",
    "# remove the id column and drop label for X dataset\n",
    "X=df_wide_full.drop(['Label', 'ID'], axis=1)\n",
    "y=df_wide_full['Label'] # chose Label for y dataset\n",
    "\n",
    "# shuffle and split into train and test sets\n",
    "np.random.seed(0)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size=0.2)\n",
    "# further split the test set into validation and test sets\n",
    "val_features, test_features, val_labels, test_labels = train_test_split(\n",
    "    test_features, test_labels, test_size=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data\n",
    "# assign label names and count label frequencies\n",
    "\n",
    "label_map = {\n",
    "    0: \"Cardiovascular / Pulmonary\",\n",
    "    1: \"Orthopedic\",\n",
    "    2: \"Radiology\",\n",
    "    3: \"General Medicine\",\n",
    "    4: \"Gastroenterology\",\n",
    "    5: \"Neurology\",\n",
    "}\n",
    "\n",
    "label_counts = (\n",
    "    train_labels.map(label_map).value_counts(sort=False).sort_index(ascending=False)\n",
    ")\n",
    "\n",
    "label_counts.plot(kind=\"barh\", color=\"tomato\", title=\"Label Counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Linear learner Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperparameters & Algorithm\n",
    "Use the [sagemaker.estimator.Estimator()](https://sagemaker.readthedocs.io/en/v1.72.0/api/training/estimators.html) function to configure the following:\n",
    "\n",
    "* train_instance_type - Type of instance to use.\n",
    "* train_instance_count - The number of instances to run the training job. For suitable algorithms that support distributed training, set an instance count of more than 1.\n",
    "* role - IAM role used to run the training job\n",
    "* train_use_spot_instances - Specify whether to use spot instances. For more information about spot training, refer to the following url: https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html\n",
    "* train_max_run - Timeout in seconds for training (default: 24 * 60 * 60). After this amount of time Amazon SageMaker terminates the job regardless of its current status.\n",
    "* train_max_wait - Timeout in seconds waiting for spot training instances\n",
    "* hyperparameters - Our hyperparameters used to train the model\n",
    "* predictor type - multiclass_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image = get_image_url(boto3.Session().region_name, 'linear_learner')\n",
    "\n",
    "hyperparameters = {\n",
    "    \"num_round\": \"150\",     # int: [1,300]\n",
    "    \"max_depth\": \"6\",     # int: [1,10]\n",
    "    \"alpha\": \"2.5\",         # float: [0,5]\n",
    "    \"eta\": \"0.2\",           # float: [0,1]\n",
    "#    \"objective\": \"binary:logistic\", # binary classification\n",
    "    \"objective\": \"multi:softmax\",    # multi class\n",
    "    \"num_class\": \"8\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"init_method\": \"normal\", # uniform or normal\n",
    "}\n",
    "\n",
    "\n",
    "# instantiate the LinearLearner estimator object\n",
    "multiclass_estimator = sagemaker.LinearLearner(\n",
    "    image_uri=training_image, # newly added!!\n",
    "    role=sagemaker.get_execution_role(), # IAM role to be used\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.m4.xlarge\",\n",
    "    predictor_type=\"multiclass_classifier\",\n",
    "    num_classes=8,\n",
    "    epochs= 50, \n",
    "    num_models = 32,                # max models to test is 32\n",
    "#    max_run=20*60,                 # Maximum allowed active runtime\n",
    "#    max_wait=30*60,                # Maximum clock time (including spot delays)\n",
    "    use_spot_instances=True,       # Use spot instances to reduce cost\n",
    "  #  hyperparameters=hyperparameters, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LL - wrap data in RecordSet objects as required by linear learner\n",
    "train_records = multiclass_estimator.record_set(train_features.values, train_labels.values, channel=\"train\")\n",
    "val_records = multiclass_estimator.record_set(val_features.values, val_labels.values, channel=\"validation\")\n",
    "test_records = multiclass_estimator.record_set(test_features.values, test_labels.values, channel=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train-the-Model\n",
    "\n",
    "To start the training job call the `estimator.fit()` function. This will start a Sagemaker training job in the background. You can also see your training job within the AWS console by going to Sagemaker -> Training jobs.\n",
    "\n",
    "Once the training job is completed, proceed to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LL - start a training job\n",
    "multiclass_estimator.fit([train_records, val_records, test_records])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy and Evaluate the Model\n",
    "After trainin the model, proceed with deploying the model (hosting it behind a real-time endpoint) so that we can start running predictions in real-time. This can be done using the `estimator.deploy()` function. (https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-deployment.html.)\n",
    "\n",
    "This deployment might take few minutes, and by default the code will wait for the deployment to complete.\n",
    "\n",
    "+ Use the Endpoints page of the SageMaker Console to check the status of the deployment\n",
    "+ You can start the Hyperparameter Optimization job in parallel - which will take a while to run too. \n",
    "+ Prediction would have to wait till the end point deployment is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LL - deploy a model hosting endpoint\n",
    "multiclass_predictor = multiclass_estimator.deploy(\n",
    "    endpoint_name=\"hhmulticlass\",\n",
    "    initial_instance_count=1, \n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    predictor_cls=sagemaker.predictor.Predictor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric evaluation\n",
    "def evaluate_metrics(predictor, test_features, test_labels):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set using the given prediction endpoint. Display classification metrics.\n",
    "    \"\"\"\n",
    "    # split the test dataset into batches and evaluate using prediction endpoint\n",
    "    prediction_batches = [predictor.predict(batch) for batch in np.array_split(test_features, 10)]\n",
    "\n",
    "    # parse protobuf responses to extract predicted labels\n",
    "    extract_label = lambda x: x.label['predicted_label'].float32_tensor.values\n",
    "    test_preds = np.concatenate([np.array([extract_label(x) for x in batch]) for batch in prediction_batches])\n",
    "    test_preds = test_preds.reshape((-1,))\n",
    "    \n",
    "    # calculate accuracy\n",
    "    accuracy = (test_preds == test_labels).sum() / test_labels.shape[0]\n",
    "    \n",
    "    # calculate recall for each class\n",
    "    recall_per_class, classes = [], []\n",
    "    for target_label in np.unique(test_labels):\n",
    "        recall_numerator = np.logical_and(test_preds == target_label, test_labels == target_label).sum()\n",
    "        recall_denominator = (test_labels == target_label).sum()\n",
    "        recall_per_class.append(recall_numerator / recall_denominator)\n",
    "        classes.append(label_map[target_label])\n",
    "    recall = pd.DataFrame({'recall': recall_per_class, 'class_label': classes})\n",
    "    recall.sort_values('class_label', ascending=False, inplace=True)\n",
    "\n",
    "    # calculate confusion matrix\n",
    "    label_mapper = np.vectorize(lambda x: label_map[x])\n",
    "    confusion_matrix = pd.crosstab(label_mapper(test_labels), label_mapper(test_preds), \n",
    "                                   rownames=['Actuals'], colnames=['Predictions'], normalize='index')\n",
    "\n",
    "    # display results\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt='.2f', cmap=\"YlGnBu\").set_title('Confusion Matrix')  \n",
    "    ax = recall.plot(kind='barh', x='class_label', y='recall', color='steelblue', title='Recall', legend=False)\n",
    "    ax.set_ylabel('')\n",
    "    print('Accuracy: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions\n",
    "\n",
    "Once the Sagemaker endpoint has been deployed, we can now run some prediction to test our endpoint. Let us test our endpoint by running some predictions on our test data and evaluating the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LL predict\n",
    "result=multiclass_predictor.predict(test_features)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LL - evaluate metrics of the model trained with default hyperparameters\n",
    "evaluate_metrics(multiclass_predictor, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classification report \n",
    "#print(classification_report(y_test,y_test_pred,labels=category_list))\n",
    "extract_label = lambda x: x.label['predicted_label'].float32_tensor.values\n",
    "test_preds = [np.array([extract_label(x) for x in result]\n",
    "test_preds = test_preds.reshape((-1,))\n",
    "print(classification_report(test_labels,test_preds,labels=label_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model from the training job\n",
    "\n",
    "After the training job is done, the model is not saved yet. Check training jobs and models in your SageMaker Console. To create a model from a training job, refer to the documentation for  *[create_model API](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_model)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a primary container with the trained model \n",
    " model_data=multiclass_estimator.create_model().model_data\n",
    " primary_container = {\n",
    "     'Image': training_image,\n",
    "     'ModelDataUrl': model_data\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare a model for hosting to run inference\n",
    " model_name = '=LL-HH-model' ## new model name\n",
    " create_model_response = sgmk_client.create_model(\n",
    "     ModelName = model_name,\n",
    "     ExecutionRoleArn = sgmk_role,\n",
    "     PrimaryContainer = primary_container,\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Inference Example\n",
    "A simplified pipeline to process an Electronic Health Record\n",
    "Combine Textract, Comprehend Medical and SageMaker endpoint to process an electronic medical resport. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "from util.Pipeline import extractTextract, extractMedical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Extract data from Textract\n",
    "\n",
    "I have used 2 use cases below. \n",
    "\n",
    "1- A medical report in English: please chose first document and uncomment the second one. If you chose this path after running the first code block below you can move to Step 2: Extract data from Comprehend Medical to skip the language detection and translation blocks.\n",
    "\n",
    "2- A medical report in German: please chose second document and uncomment the first one\n",
    "    - first use Translate to create a English translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFprefix='hhtestdata' # bucket name if you use test data from s3- customize name if you test this code\n",
    "\n",
    "# Check the 2 use cases seperately (you should chose either Use case 1 or Use case 2\n",
    "# If you chose use case 1, you can skip the next few blocks and directly go to Step 2: Extract data from Comprehend Medical\n",
    "# Use case 1 - English language report\n",
    "fileName =  'sample_report_1.pdf' \n",
    "\n",
    "# Use case 2 - German language report\n",
    "#fileName =  'sample_report_2.pdf' \n",
    "\n",
    "fileUploadPath = os.path.join(\"./data\", fileName) # if you upload from working dir\n",
    "#fileUploadPath = os.path.join(PDFprefix, fileName) # if you upload from a s3 bucket\n",
    "print(\"EHR file to be processed is at \", fileUploadPath)\n",
    "\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket_name).Object(fileName).upload_file(\n",
    "    fileUploadPath\n",
    ")\n",
    "\n",
    "doc=extractTextract(bucket_name,fileName) # extract pdf file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # read full text\n",
    "print(\"Total length of document is\", len(doc.pages))\n",
    "idx = 1\n",
    "full_text = \"\"\n",
    "for page in doc.pages:\n",
    "    print(f\"Results from page {idx}: \\n\", page.text)\n",
    "    full_text += page.text\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect languagge\n",
    "comprehend_client = boto3.client(service_name=\"comprehend\", region_name=\"us-east-1\")\n",
    "response = comprehend_client.detect_dominant_language(Text=full_text).get(\n",
    "    \"Languages\", []\n",
    ")\n",
    "for language in response:\n",
    "    print(\n",
    "        f\"Detected language is {language.get('LanguageCode', [])}, with a confidence score of {language.get('Score', [])}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if language is de then translate to en\n",
    "if language.get('LanguageCode', [])=='de':\n",
    "    translate = boto3.client(service_name='translate', region_name='us-east-1', use_ssl=True)\n",
    "    result = translate.translate_text(Text=full_text[:5000], SourceLanguageCode=\"de\", TargetLanguageCode=\"en\")\n",
    "    enFullText = result.get('TranslatedText')\n",
    "    print('TranslatedText: ' + enFullText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Extract data from Comprehend Medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if language.get('LanguageCode', [])=='de':\n",
    "    comprehendResponse=extractMedical(enFullText)\n",
    "else:\n",
    "    comprehendResponse=extractMedical(doc)\n",
    "df_cm=extractMC_v2(comprehendResponse[0]) # create dataframe with feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Organize the extracted json file into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclist, df_cm2=retrieve_mcList(df_cm, nFeature=40,threshold=0.8) # use same nfeatures and threshold as before\n",
    "df_cm2=df_mc_generator_slim(df_cm2)\n",
    "df_cm2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Prediction with the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataset with same feature list as in our dataset used to train\n",
    "df_final=test_features.iloc[0:0,0:] \n",
    "#print(df_final)\n",
    "\n",
    "# chose from the comprehend medical extracted features only features as in the train dataset\n",
    "df_final=df_final.append(df_cm2[df_cm2.columns.intersection(df_final.columns)])\n",
    "\n",
    "df_final=df_final.fillna(0)\n",
    "df_final=df_final.apply(pd.to_numeric, downcast='float', errors='coerce')\n",
    "#print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. predict with trained model\n",
    "result=multiclass_predictor.predict(df_final.values)\n",
    "# result=LL-HH-model.predict(df_final.values) # using setup model\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv format input string to predict using endpoint\n",
    "import json\n",
    "#print(df_final.values)\n",
    "s = json.dumps(df_final.values.tolist())\n",
    "#print(s[0:])\n",
    "td=s[0:]\n",
    "td=td.replace('[', '')\n",
    "td=td.replace(']', '')\n",
    "print(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a test record\n",
    "#td='0.0, 0.0, 0.0, 0.0, 0.0, 0.6807340383529663, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9984696507453918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0'\n",
    "\n",
    "# 2. predict using the endpoint\n",
    "endpoint = 'hhmulticlass'\n",
    "runtime = boto3.Session().client('sagemaker-runtime')\n",
    "\n",
    "# Send input data to get prediction via InvokeEndpoint API\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint, ContentType='text/csv', Body=td)\n",
    "\n",
    "# Unpack response\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "SageMaker linear learner algorithms performed well with the limited dataset. It would be intersting to compare results with some other models. \n",
    "\n",
    "At the end inference results showed the predicted classification which can be used for providing health recommendations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Clean up resources\n",
    "### Delete the endpoint and configuration if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_estimator.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the generated files S3 bucket files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete all the content in the emr-mtSample folder. Check S3 before deleting it\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "bucket.objects.filter(Prefix=bucket_prefix).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Delete all the content in the PDF folder \n",
    "bucket.objects.filter(Prefix=PDFprefix).delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practice:\n",
    " 1. Delete the buckets created from testing\n",
    " 2. Shut down your notebook instance if you are not planning to explore more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
